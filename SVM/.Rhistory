?svm
rm(list= ls())
cl <- makeCluster(detectCores())
registerDoParallel(cl)
library(caret)
library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('/Users/deepanshparab/Desktop/cs-513Project/dataset/train-images.idx3-ubyte')
test <<- load_image_file('/Users/deepanshparab/Desktop/cs-513Project/dataset/t10k-images.idx3-ubyte')
train$y <<- load_label_file('/Users/deepanshparab/Desktop/cs-513Project/dataset/train-labels.idx1-ubyte')
test$y <<- load_label_file('/Users/deepanshparab/Desktop/cs-513Project/dataset/t10k-labels.idx1-ubyte')
}
train <- data.frame()
test <- data.frame()
load_mnist()
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train$x <- train$x / 255
inTrain = data.frame(y=train$y, train$x)
inTrain$y <- as.factor(inTrain$y)
?createDataPartition
trainIndex = createDataPartition(inTrain$y, p = 0.60,list=FALSE)
training = inTrain[trainIndex,]
cv = inTrain[-trainIndex,]
fit <- train(y ~ ., data = head(training, 6000), method = 'svmRadial', tuneGrid = data.frame(sigma=0.0107249, C=1))
fit <- train(y ~ ., data = head(training, 6000), method = 'svmRadial', tuneGrid = data.frame(sigma=0.0107249, C=1))
results <- predict(fit, newdata = head(cv, 6000))
confusionMatrix(results, head(cv$y, 6000))
show_digit(as.matrix(training[1003,2:785]))
show_digit(as.matrix(training[1000,2:785]))
prediction <- predict(fit, newdata = training[0:6000,])
trained_model<- training[1:6000,1]
table(prediction,trained_model)
sum_acc1<-sum(diag(table(prediction,trained_model)))/6000
sum_acc1
rm(list=ls())
library(h2o)
train <- read.csv ("/Users/deepanshparab/Desktop/cs-513Project/h20/data/train.csv")
m = matrix(unlist(train[10,-1]), nrow = 28, byrow = TRUE)
library (caret)
inTrain<- createDataPartition(train$label, p=0.8, list=FALSE)
training<-train[inTrain,]
testing<-train[-inTrain,]
local.h2o <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, nthreads=-1)
training <- train[0:6000,]
testing  <- testing[0:1500,]
training[,1]<-as.factor(training[,1])
trData<-as.h2o(training)
tsData<-as.h2o(testing)
res.dl <- h2o.deeplearning(x = 2:785, y = 1, trData, activation = "Tanh", hidden=rep(160,5),epochs = 20)
pred.dl<-h2o.predict(object=res.dl, newdata=tsData[,-1])
pred.dl.df<-as.data.frame(pred.dl)
summary(pred.dl)
test_labels<-testing[,1]
sum_acc<-sum(diag(table(test_labels,pred.dl.df[,1])))
accuracy <- sum_acc/nrow(testing)
accuracy
(table(test_labels,pred.dl.df[,1]))
rm(list=ls())
library(h2o)
train <- read.csv ("/Users/deepanshparab/Desktop/cs-513Project/h20/data/train.csv")
m = matrix(unlist(train[10,-1]), nrow = 28, byrow = TRUE)
# partitioning the datasets
library (caret)
inTrain<- createDataPartition(train$label, p=0.8, list=FALSE)
training<-train[inTrain,]
testing<-train[-inTrain,]
#start a local h2o cluster
local.h2o <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, nthreads=-1)
training <- train[0:6000,]
testing  <- testing[0:1500,]
training[,1]<-as.factor(training[,1])
trData<-as.h2o(training)
tsData<-as.h2o(testing)
library(randomForest)
prac.rf<-randomForest(label~.,training)
train_label <- training[,1]
library(neuralnet)
nn_new = neuralnet(formula = training$label~., data = infert,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
nn_new = neuralnet(formula = label~., data = training,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
nn_new = neuralnet(label, data = training,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
nn_new = neuralnet(training$label, data = training,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
nn_new = neuralnet(formula = label~ ., data = training,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
nn_new = neuralnet(formula = label~ ., training,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
nn_new = neuralnet(formula = training~ ., training,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
nn_new = neuralnet(formula = training~, training,  hidden = 2,learningrate = 0.01, algorithm = "backprop" ,err.fct = "ce", linear.output = FALSE)
train <- read.csv ("/Users/deepanshparab/Desktop/cs-513Project/h20/data/train.csv")
trainDigits <- read.csv("/Users/deepanshparab/Desktop/cs-513Project/knn/data/mnist_train.csv")
View(trainDigits)
rm(list=ls())
trainDigits <- read.csv("/Users/deepanshparab/Desktop/cs-513Project/knn/data/mnist_train.csv")
testDigits <- read.csv("/Users/deepanshparab/Desktop/cs-513Project/knn/data/mnist_test.csv")
View(trainDigits)
View(testDigits)
train <- read.csv ("/Users/deepanshparab/Desktop/cs-513Project/h20/data/train.csv")
library (caret)
inTrain<- createDataPartition(train$label, p=0.8, list=FALSE)
training<-train[inTrain,]
testing<-train[-inTrain,]
local.h2o <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, nthreads=-1)
training <- train[0:6000,]
testing  <- testing[0:1500,]
training[,1]<-as.factor(training[,1])
prac.rf<-randomForest(label~.,training,ntrees=200, mtries = 28)
accuracy <- sum(diag(table(testing$label,predict(prac.rf,newdata=testing[,-1]))))/nrow(testing)
accuracy
prac.rf<-randomForest(label~.,training,ntrees=500, mtries = 28)
accuracy <- sum(diag(table(testing$label,predict(prac.rf,newdata=testing[,-1]))))/nrow(testing)
accuracy
